{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning 3rd Project\n",
    "### Authors: Guilherme Cepeda - 62931, Pedro Serrano - 54853\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this third assignment, we were asked to apply reinforcement learning to the Mountain Cart problem, from Gymnasium. We will split this in two parts, one where we implement Q-Learning, and one where we implement Deep Q-Learning, as requested in the statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings as w\n",
    "import gymnasium as gym\n",
    "import pickle\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment,suite_gym\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **Mountain Car reinforcemet learning problem** the challenge lies in the continuous control problem of getting the car to move uphill by applying appropriate forces. There's no randomness in the transitions between states in the same way as it might be in a discrete grid world like FrozenLake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\") # rendered to an rbg array, returned as a NumPy array containing pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.imshow(env.render())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we started by understanding the possible states and actions of the environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.2  -0.07], [0.6  0.07], (2,), float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space #Position of the car along the x-axis, Min: -1.2 Max: 0.6\n",
    "                      #Velocity of the car, Min:-0.07 Max: 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "\n",
    "3 actions:\n",
    "* Drive left\n",
    "* Stay neutral\n",
    "* Drive right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) \n",
    "print(\"\\n\",env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample() # generates a random action sample between 0(left), 1 (neutral) and 2(right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.5742453 ,  0.00311769], dtype=float32), -1.0, False, False, {})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.action_space.sample())# executes an action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q - Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Q-Learning** algorithm is an model-free, off-policy method of doing **Reinforcement Learning**. This means we will not be estimating the transition matrix and the rewards, and will be going straight after an optimal policy.\n",
    "\n",
    "We have **two environments**, the train and evaluation/test environment as this practice helps ensure that our agent is able to generalize its learned policy to unseen situations during the evaluation/testing phase.\n",
    "\n",
    "How do we do this?\n",
    "We create a Q-table, which is a lookup table of states by actions, where, in each entry [state[i], action[i]] we have stored the optimal policy for that specific request. We estimate each Q value as the sum of the immediate reward, plus the maximum Q value of the possible future actions. We usualy add a weight - the discount factor - to this second part to balance out how much we want to reward the current reward. We expect the optimal discount factor in this problem to be fairly high - its like this is most cases, we believe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As presented in the statement, the space is continuous, so we will need to turn it into a discrete space. \n",
    "\n",
    "We use the numpy linspace function to separate the entire range of the position and velocity scalers in equal parts. Here we initilly picked 5 (yes, it was very small), and tested bigger and bigger numbers until reaching the optimum value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we initialize some of the models parameters\n",
    "\n",
    "The Q-table starts off by all zeros - we also tested by starting with random numbers, but it didnt improve (later we realized this was useless, since we were starting our epsilon at 1)\n",
    "\n",
    "The treshold is an alternitive to having a fixed number of episodes - instead we pick a very low treshold, and if we dont improve more than the threshold, we stop running.\n",
    "\n",
    "We have talked about the discount factor before, but here we also initizalize the learning rate - still dont know what this is specifically.\n",
    "\n",
    "We start our epsilon at 1, and keep decreasing with every episode. The epsilon gives our how much of our decision is going to be random, meaning we start off with a completely random decision, and make them less random with every episode by using our Q-table\n",
    "\n",
    "The rewards per episode is just an array, initialized at all zeros, where we will be updating our rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_test(training, episodes, environment):\n",
    "\n",
    "    # Divide position and velocity into segments\n",
    "    position_space = np.linspace(environment.observation_space.low[0], environment.observation_space.high[0], 20)    # position between -1.2 and 0.6\n",
    "    velocity_space = np.linspace(environment.observation_space.low[1], environment.observation_space.high[1], 20)    # velocity between -0.07 and 0.07\n",
    "\n",
    "    if(training):\n",
    "        #if we are training, we begin with an empty Q-table. Alternitivly, we can initialize random numbers\n",
    "        q_table = np.zeros((len(position_space), len(velocity_space), environment.action_space.n)) # initialize the q table with dimension 20x20x3\n",
    "    else:\n",
    "        #Otherwise, we just load the last updated Q-table from the traiinng phase\n",
    "        f = open('mountain_car.pkl', 'rb')\n",
    "        q_table = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    #set the threshold number for checking the convergence of the value function\n",
    "    threshold = 1e-10 # 1e-20 no effect on the episodes\n",
    "                     # 1e-5 the graph becomes mostly straight and destroys the test no longer works so threshold > 1e-5\n",
    "\n",
    "    alpha = 0.9 # alpha = learning rate\n",
    "    gamma = 0.9 # gamma = discount factor\n",
    "\n",
    "    epsilon = 1 # 100% random actions\n",
    "    epsilon_decay_rate = 2/episodes # epsilon decay rate\n",
    "    #epsilon_decay_rate = 0.99975\n",
    "\n",
    "    random_n_g = np.random.default_rng()   # random number generator\n",
    "\n",
    "    rewards_per_episode = np.zeros(episodes) # rewards per episode\n",
    "\n",
    "    for i in range(episodes):\n",
    "\n",
    "        state = environment.reset()[0]      # Starting position, starting velocity always 0\n",
    "        state_p = np.digitize(state[0], position_space) #digitize function to find which segment the value belongs to\n",
    "        state_v = np.digitize(state[1], velocity_space)\n",
    "\n",
    "        terminated = False # when terminated is true it means we reached our goal\n",
    "\n",
    "        rewards = 0 # each reward is -1\n",
    "\n",
    "        previous_q_table = np.copy(q_table)  # Copy of the Q-table from the previous episode\n",
    "\n",
    "        while(not terminated and rewards>-1000):\n",
    "\n",
    "            if training and random_n_g.random() < epsilon:\n",
    "                # Choose random action (0=drive left, 1=stay neutral, 2=drive right)\n",
    "                action = environment.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state_p, state_v, :]) # finds the index of the action that has the highest Q-value for the specified state in the Q-values array\n",
    "\n",
    "            new_state,reward,terminated,_,_ = environment.step(action)\n",
    "            \n",
    "            new_state_p = np.digitize(new_state[0], position_space)\n",
    "            new_state_v = np.digitize(new_state[1], velocity_space)\n",
    "\n",
    "            if training:\n",
    "                q_table[state_p, state_v, action] = q_table[state_p, state_v, action] + alpha * (\n",
    "                    reward + gamma *np.max(q_table[new_state_p, new_state_v,:]) - q_table[state_p, state_v, action]\n",
    "                ) # calculates the q value and updates the q table\n",
    "\n",
    "            state = new_state\n",
    "            state_p = new_state_p\n",
    "            state_v = new_state_v\n",
    "\n",
    "            rewards+=reward\n",
    "\n",
    "        epsilon = max(epsilon - epsilon_decay_rate, 0)\n",
    "        '''if epsilon > 0.001:\n",
    "            epsilon *= epsilon_decay_rate \n",
    "        else:\n",
    "            epsilon = 0.001'''\n",
    "\n",
    "        rewards_per_episode[i] = rewards\n",
    "\n",
    "        # Check for convergence based on the change in Q-values\n",
    "        if training and i > 0:\n",
    "            q_change = np.mean(np.abs(q_table - previous_q_table))\n",
    "            if q_change < threshold:\n",
    "                print(f\"Convergence reached. Stopping at episode {i}.\")\n",
    "                break\n",
    "            previous_q_table = np.copy(q_table)\n",
    "\n",
    "    environment.close()\n",
    "\n",
    "    # Save Q table to file\n",
    "    if training:\n",
    "        f = open('mountain_car.pkl','wb')\n",
    "        pickle.dump(q_table, f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    #Plot the results\n",
    "    mean_rewards = np.zeros(episodes)\n",
    "    for t in range(episodes):\n",
    "        mean_rewards[t] = np.mean(rewards_per_episode[max(0, t-100):(t+1)]) #  technique to smooth out fluctuations in the learning curve to provide a more stable measure of the agent's performance over time.\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.savefig(f'mountain_car.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show a plot, displaying how the rewards improve with the episodes.\n",
    "\n",
    "We can see its learning, and then stops at a little over -200. Why is the number negative? We dont assign a reward to finishing, and we decrease our reward for every step - this is to make the algorithm choose faster paths, meaning our car took a little less than 200 steps to get to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training\n",
    "train_env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
    "q_learning_test(True,5000,train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we were just training the model. Now, lets test how good our Q-table really is. \n",
    "\n",
    "Here, we use the gym package to render the GUI, and do the same plot we did before, but this time, since the values are close together, we can cleary see we get a maximum of -145, meaning we can get our car to the top with 145 steps.(CHECAR ESTA CONCLUSAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "eval_env = gym.make('MountainCar-v0', render_mode=\"human\")# will be rendered in a window or on the screen using the standard rendering mechanism (GUI) of the system\n",
    "#test/evaluation\n",
    "q_learning_test(False, 10,eval_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning\n",
    "\n",
    "* When a neural network is created it has a random set of weight and bias.\n",
    "\n",
    "Again two environments are instantiated, one for training and one for evaluation/testing.\n",
    "\n",
    "There are two ways of doing this, with tensorflow and pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#two environments instanciated\n",
    "train_env_dql = gym.make('MountainCar-v0')\n",
    "\n",
    "# Divide position and velocity into segments\n",
    "position_space = np.linspace(train_env_dql.observation_space.low[0], train_env_dql.observation_space.high[0], 20)    # position between -1.2 and 0.6\n",
    "velocity_space = np.linspace(train_env_dql.observation_space.low[1], train_env_dql.observation_space.high[1], 20)    # velocity between -0.07 and 0.07\n",
    "\n",
    "ACTIONS = [0, 1, 2]             # 0=push left, 1=no push, 2=push right, chage to Letters if needed\n",
    "\n",
    "train_env_dql.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_states, h1_nodes, out_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define network layers\n",
    "        self.fc1 = nn.Linear(in_states, h1_nodes)   # first fully connected layer\n",
    "        self.out = nn.Linear(h1_nodes, out_actions) # ouptut layer w\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # Apply rectified linear unit (ReLU) activation\n",
    "        x = self.out(x)         # Calculate output\n",
    "        return x\n",
    "\n",
    "'''\n",
    "Converts an state (int) to a tensor representation.\n",
    "For example, the FrozenLake 4x4 map has 4x4=16 states numbered from 0 to 15. \n",
    "\n",
    "Parameters: state=5, num_states=16\n",
    "Return: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "'''\n",
    "def state_to_dqn_input(state:int, num_states:int)->torch.Tensor:\n",
    "    input_tensor = torch.zeros(num_states)\n",
    "    input_tensor[state] = 1\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "# Print DQN: state, best action, q values\n",
    "def print_dqn(dqn):\n",
    "    # Get number of input nodes\n",
    "    num_states = dqn.fc1.in_features\n",
    "    print(num_states)\n",
    "\n",
    "    # Loop each state and print policy to console\n",
    "    for s in range(num_states):\n",
    "        #  Format q values for printing\n",
    "        q_values = ''\n",
    "        for q in dqn(state_to_dqn_input(s, num_states)).tolist():\n",
    "            q_values += \"{:+.2f}\".format(q)+' '  # Concatenate q values, format to 2 decimals\n",
    "        q_values=q_values.rstrip()              # Remove space at the end\n",
    "\n",
    "        # Map the best action to L D R U\n",
    "        best_action = dqn(state_to_dqn_input(s, num_states)).argmax()\n",
    "\n",
    "        # Print policy in the format of: state, action, q values\n",
    "        # The printed layout matches the FrozenLake map.\n",
    "        print(f'{s:02},{best_action},[{q_values}]', end=' ')         \n",
    "        if (s+1)%4==0:\n",
    "            print() # Print a newline every 4 states\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optimize policy network\n",
    "def optimize(mini_batch, policy_dqn, target_dqn, discount_factor_g, loss_fn, optimizer):\n",
    "    # Get number of input nodes\n",
    "    num_states = policy_dqn.fc1.in_features\n",
    "\n",
    "    current_q_list = []\n",
    "    target_q_list = []\n",
    "\n",
    "    for state, action, new_state, reward, terminated in mini_batch:\n",
    "\n",
    "        if terminated: \n",
    "            # When in a terminated state, target q value should be set to the reward.\n",
    "            target = torch.FloatTensor([reward])\n",
    "        else:\n",
    "            # Calculate target q value \n",
    "            with torch.no_grad():\n",
    "                target = torch.FloatTensor(\n",
    "                    reward + discount_factor_g * target_dqn(state_to_dqn_input(new_state, num_states)).max()\n",
    "                )\n",
    "\n",
    "        # Get the current set of Q values\n",
    "        current_q = policy_dqn(state_to_dqn_input(state, num_states))\n",
    "        current_q_list.append(current_q)\n",
    "\n",
    "        # Get the target set of Q values\n",
    "        target_q = target_dqn(state_to_dqn_input(state, num_states)) \n",
    "        # Adjust the specific action to the target that was just calculated\n",
    "        target_q[action] = target\n",
    "        target_q_list.append(target_q)\n",
    "            \n",
    "    # Compute loss for the whole minibatch\n",
    "    loss = loss_fn(torch.stack(current_q_list), torch.stack(target_q_list))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for the deep q-learning algorithm\n",
    "def deep_q_learning_training(episodes):\n",
    "    #hyperparameters \n",
    "    learning_rate_a = 0.001         # learning rate (alpha)\n",
    "    discount_factor_g = 0.9         # discount rate (gamma)    \n",
    "    network_sync_rate = 10          # number of steps the agent takes before syncing the policy and target network\n",
    "    replay_memory_size = 1000       # size of replay memory\n",
    "    mini_batch_size = 32            # size of the training data set sampled from the replay memory\n",
    "\n",
    "    random_n_g = np.random.default_rng()   # random number generator\n",
    "    n_states = train_env_dql.observation_space.shape[0] #len(position_space) + len(velocity_space)# the neural network must kow the dimensions correctly #train_env_dql.observation_space.shape[0]\n",
    "    n_actions = train_env_dql.action_space.n\n",
    "\n",
    "    # Neural Network\n",
    "    loss_fn = nn.MSELoss()          # NN Loss function. MSE=Mean Squared Error can be swapped to something else.\n",
    "    optimizer = None                # NN Optimizer. Initialize later.\n",
    "\n",
    "    epsilon = 1 # as before epsilon = 1 is 100% random actions\n",
    "\n",
    "\n",
    "    #replay memory\n",
    "    replay_mem = deque([], maxlen=replay_memory_size)\n",
    "\n",
    "    # Create policy and target network. Number of nodes in the hidden layer can be adjusted.\n",
    "    policy_dqn = DQN(in_states=n_states, h1_nodes=n_states, out_actions=n_actions)\n",
    "    target_dqn = DQN(in_states=n_states, h1_nodes=n_states, out_actions=n_actions)\n",
    "    #target_dqn = nn.Linear(n_states,n_actions)\n",
    "\n",
    "    # Make the target and policy networks the same (copy weights/biases from one network to the other)\n",
    "    target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "    \n",
    "    print('Policy (random, before training):')\n",
    "    print_dqn(policy_dqn)\n",
    "\n",
    "    # Policy network optimizer Adam\n",
    "    optimizer = torch.optim.Adam(policy_dqn.parameters(), lr=learning_rate_a)\n",
    "\n",
    "    # List to keep track of rewards collected per episode. Initialize list to 0's.\n",
    "    rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "    # List to keep track of epsilon decay\n",
    "    epsilon_history = []\n",
    "\n",
    "    # Track number of steps taken. Used for syncing policy => target network.\n",
    "    step_count = 0\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = train_env_dql.reset()  # Initialize to initial state\n",
    "        #state_p = np.digitize(state[0], position_space) #digitize function to find which segment the value belongs to\n",
    "        #state_v = np.digitize(state[1], velocity_space)\n",
    "        terminated = False   # True when episode is terminated\n",
    "\n",
    "        rewards = 0 # each reward is -1\n",
    "\n",
    "        # Agent takes actions until the episode is terminated\n",
    "        while (not terminated and rewards>-1000):\n",
    "            # Select action based on epsilon-greedy\n",
    "            if random_n_g.random() < epsilon:\n",
    "                action = train_env_dql.action_space.sample()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    # Compute Q-values using the policy network\n",
    "                    q_values = policy_dqn(state_to_dqn_input(state, n_states))\n",
    "\n",
    "                    # Extract the action as a scalar\n",
    "                    action = q_values.argmax().item()\n",
    "\n",
    "            # Execute action\n",
    "            new_state, reward, terminated,_,_= train_env_dql.step(action)\n",
    "\n",
    "            #new_state_p = np.digitize(new_state[0], position_space)\n",
    "            #new_state_v = np.digitize(new_state[1], velocity_space)\n",
    "\n",
    "            # Save experience into memory\n",
    "            replay_mem.append((state, action, new_state, reward, terminated))\n",
    "\n",
    "            # Move to the next state\n",
    "            state = new_state\n",
    "            #state_p = new_state_p\n",
    "            #state_v = new_state_v\n",
    "\n",
    "            # Increment step counter\n",
    "            step_count += 1\n",
    "\n",
    "            rewards+=reward\n",
    "\n",
    "        # Keep track of the rewards collected per episode.\n",
    "        rewards_per_episode[i] = reward\n",
    "\n",
    "        # Check if enough experience has been collected\n",
    "        if len(replay_mem) > mini_batch_size:\n",
    "            mini_batch = r.sample(replay_mem, mini_batch_size)\n",
    "            optimize(mini_batch, policy_dqn, target_dqn,discount_factor_g,loss_fn,optimizer)\n",
    "\n",
    "            # Decay epsilon\n",
    "            epsilon = max(epsilon - 1 / episodes, 0)\n",
    "            epsilon_history.append(epsilon)\n",
    "\n",
    "            # Copy policy network to target network after a certain number of steps\n",
    "            if step_count > network_sync_rate:\n",
    "                target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "                step_count = 0\n",
    "    \n",
    "    # Close environment\n",
    "    train_env_dql.close()\n",
    "\n",
    "    # Save policy\n",
    "    torch.save(policy_dqn.state_dict(), \"mountain_car_dql.pt\")\n",
    "\n",
    "    # Create new graph\n",
    "    plt.figure(1)\n",
    "\n",
    "    # Plot average rewards (Y-axis) vs episodes (X-axis)\n",
    "    sum_rewards = np.zeros(episodes)\n",
    "    for x in range(episodes):\n",
    "        sum_rewards[x] = np.sum(rewards_per_episode[max(0, x - 100):(x + 1)])\n",
    "    plt.subplot(121)  # plot on a 1 row x 2 col grid, at cell 1\n",
    "    plt.plot(sum_rewards)\n",
    "\n",
    "    # Plot epsilon decay (Y-axis) vs episodes (X-axis)\n",
    "    plt.subplot(122)  # plot on a 1 row x 2 col grid, at cell 2\n",
    "    plt.plot(epsilon_history)\n",
    "\n",
    "    # Save plots\n",
    "    plt.savefig('mountain_car_dql.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy (random, before training):\n",
      "2\n",
      "00,1,[-0.60 +0.67 +0.32] 01,1,[-0.86 +0.78 +0.36] "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdeep_q_learning_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[107], line 93\u001b[0m, in \u001b[0;36mdeep_q_learning_training\u001b[1;34m(episodes)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay_mem) \u001b[38;5;241m>\u001b[39m mini_batch_size:\n\u001b[0;32m     92\u001b[0m     mini_batch \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39msample(replay_mem, mini_batch_size)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiscount_factor_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Decay epsilon\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(epsilon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m episodes, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[76], line 75\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(mini_batch, policy_dqn, target_dqn, discount_factor_g, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     70\u001b[0m         target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\n\u001b[0;32m     71\u001b[0m             reward \u001b[38;5;241m+\u001b[39m discount_factor_g \u001b[38;5;241m*\u001b[39m target_dqn(state_to_dqn_input(new_state, num_states))\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Get the current set of Q values\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m current_q \u001b[38;5;241m=\u001b[39m policy_dqn(\u001b[43mstate_to_dqn_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     76\u001b[0m current_q_list\u001b[38;5;241m.\u001b[39mappend(current_q)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Get the target set of Q values\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[76], line 24\u001b[0m, in \u001b[0;36mstate_to_dqn_input\u001b[1;34m(state, num_states)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate_to_dqn_input\u001b[39m(state:\u001b[38;5;28mint\u001b[39m, num_states:\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     23\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_states)\n\u001b[1;32m---> 24\u001b[0m     \u001b[43minput_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_tensor\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "#training \n",
    "deep_q_learning_training(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Mountain Car environment with the learned policy\n",
    "def deep_q_learning_test(episodes):\n",
    "    # Create Mountain Car instance\n",
    "    eval_env_dql = gym.make('MountainCar-v0', render_mode=\"human\")\n",
    "    n_states = len(position_space) + len(velocity_space)\n",
    "    n_actions = eval_env_dql.action_space.n\n",
    "\n",
    "    # Load learned policy\n",
    "    policy_dqn = DQN(in_states=n_states, h1_nodes=n_states, out_actions=n_actions)\n",
    "    policy_dqn.load_state_dict(torch.load(\"mountain_car_dql.pt\"))\n",
    "    policy_dqn.eval()    # switch model to evaluation mode\n",
    "\n",
    "    \n",
    "\n",
    "    print('Policy (trained):')\n",
    "    print_dqn(policy_dqn)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = eval_env_dql.reset()[0]  # Initialize to state 0\n",
    "        terminated = False      # True when agent falls in hole or reached goal        \n",
    "\n",
    "        rewards = 0 # each reward is -1\n",
    "\n",
    "        # Agent navigates map until it reaches the goal (flag) or it rewaches a reward of -1000\n",
    "        while(not terminated and rewards>-1000):  \n",
    "            # Select best action   \n",
    "            with torch.no_grad():\n",
    "                action = policy_dqn(state_to_dqn_input(state, n_states)).argmax().item()\n",
    "\n",
    "            # Execute action\n",
    "            state,reward,terminated,_ = env.step(action)\n",
    "\n",
    "            rewards+=reward\n",
    "\n",
    "    eval_env_dql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -200.0, Epsilon: 0.995\n",
      "Episode 10, Total Reward: -200.0, Epsilon: 0.946354579813443\n",
      "Episode 20, Total Reward: -200.0, Epsilon: 0.9000874278732445\n",
      "Episode 30, Total Reward: -200.0, Epsilon: 0.8560822709551227\n",
      "Episode 40, Total Reward: -200.0, Epsilon: 0.8142285204175609\n",
      "Episode 50, Total Reward: -200.0, Epsilon: 0.7744209942832988\n",
      "Episode 60, Total Reward: -200.0, Epsilon: 0.736559652908221\n",
      "Episode 70, Total Reward: -200.0, Epsilon: 0.7005493475733617\n",
      "Episode 80, Total Reward: -200.0, Epsilon: 0.6662995813682115\n",
      "Episode 90, Total Reward: -200.0, Epsilon: 0.6337242817644086\n",
      "Episode 100, Total Reward: -200.0, Epsilon: 0.6027415843082742\n",
      "Episode 110, Total Reward: -200.0, Epsilon: 0.5732736268885887\n",
      "Episode 120, Total Reward: -200.0, Epsilon: 0.5452463540625918\n",
      "Episode 130, Total Reward: -200.0, Epsilon: 0.5185893309484582\n",
      "Episode 140, Total Reward: -200.0, Epsilon: 0.4932355662165453\n",
      "Episode 150, Total Reward: -200.0, Epsilon: 0.46912134373457726\n",
      "Episode 160, Total Reward: -200.0, Epsilon: 0.446186062443672\n",
      "Episode 170, Total Reward: -200.0, Epsilon: 0.42437208406280985\n",
      "Episode 180, Total Reward: -200.0, Epsilon: 0.4036245882390106\n",
      "Episode 190, Total Reward: -200.0, Epsilon: 0.38389143477919885\n",
      "Episode 200, Total Reward: -200.0, Epsilon: 0.36512303261753626\n",
      "Episode 210, Total Reward: -200.0, Epsilon: 0.3472722151889232\n",
      "Episode 220, Total Reward: -200.0, Epsilon: 0.3302941218954743\n",
      "Episode 230, Total Reward: -200.0, Epsilon: 0.3141460853680822\n",
      "Episode 240, Total Reward: -200.0, Epsilon: 0.2987875242397482\n",
      "Episode 250, Total Reward: -200.0, Epsilon: 0.28417984116121187\n",
      "Episode 260, Total Reward: -200.0, Epsilon: 0.2702863258025825\n",
      "Episode 270, Total Reward: -200.0, Epsilon: 0.2570720625972084\n",
      "Episode 280, Total Reward: -200.0, Epsilon: 0.24450384299593592\n",
      "Episode 290, Total Reward: -200.0, Epsilon: 0.23255008201124722\n",
      "Episode 300, Total Reward: -200.0, Epsilon: 0.2211807388415433\n",
      "Episode 310, Total Reward: -200.0, Epsilon: 0.21036724137609603\n",
      "Episode 320, Total Reward: -200.0, Epsilon: 0.2000824143909432\n",
      "Episode 330, Total Reward: -200.0, Epsilon: 0.1903004112552766\n",
      "Episode 340, Total Reward: -200.0, Epsilon: 0.18099664897669618\n",
      "Episode 350, Total Reward: -200.0, Epsilon: 0.17214774642209296\n",
      "Episode 360, Total Reward: -200.0, Epsilon: 0.16373146555890544\n",
      "Episode 370, Total Reward: -200.0, Epsilon: 0.1557266555690826\n",
      "Episode 380, Total Reward: -200.0, Epsilon: 0.14811319969530845\n",
      "Episode 390, Total Reward: -200.0, Epsilon: 0.14087196468590776\n",
      "Episode 400, Total Reward: -200.0, Epsilon: 0.13398475271138335\n",
      "Episode 410, Total Reward: -200.0, Epsilon: 0.12743425563174798\n",
      "Episode 420, Total Reward: -200.0, Epsilon: 0.12120401149972035\n",
      "Episode 430, Total Reward: -200.0, Epsilon: 0.11527836319047392\n",
      "Episode 440, Total Reward: -200.0, Epsilon: 0.10964241905397228\n",
      "Episode 450, Total Reward: -200.0, Epsilon: 0.1042820154910064\n",
      "Episode 460, Total Reward: -200.0, Epsilon: 0.09918368135888474\n",
      "Episode 470, Total Reward: -200.0, Epsilon: 0.0943346041173244\n",
      "Episode 480, Total Reward: -200.0, Epsilon: 0.08972259762946533\n",
      "Episode 490, Total Reward: -200.0, Epsilon: 0.08533607153708872\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MountainCarEnv.__init__() got an unexpected keyword argument 'render'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 145\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m    143\u001b[0m total_rewards \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtrain_agent(episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMountainCar-v0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Test the agent\u001b[39;00m\n\u001b[0;32m    147\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_agent()\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\gym\\envs\\registration.py:676\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake\u001b[39m(\u001b[38;5;28mid\u001b[39m: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\gym\\envs\\registration.py:520\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec(path)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# Construct the environment\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\gym\\envs\\registration.py:140\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_point)\n\u001b[1;32m--> 140\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Make the environment aware of which spec it came from.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m spec \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: MountainCarEnv.__init__() got an unexpected keyword argument 'render'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# Neural network model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Experience replay buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return (\n",
    "            torch.FloatTensor(states),\n",
    "            torch.LongTensor(actions),\n",
    "            torch.FloatTensor(rewards),\n",
    "            torch.FloatTensor(next_states),\n",
    "            torch.BoolTensor(dones)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# Deep Q-Learning agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, env, buffer_capacity=10000, batch_size=64, gamma=0.99, lr=1e-3, epsilon_decay=0.995):\n",
    "        self.env = env\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.buffer = ReplayBuffer(buffer_capacity)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = DQN(env.observation_space.shape[0], env.action_space.n).to(self.device)\n",
    "        self.target_model = DQN(env.observation_space.shape[0], env.action_space.n).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.model(torch.FloatTensor(state).to(self.device))\n",
    "                return q_values.argmax().item()  # Exploit\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)\n",
    "\n",
    "        current_q_values = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "        target_q_values = rewards.unsqueeze(1) + self.gamma * (~dones.unsqueeze(1)) * \\\n",
    "                  self.target_model(next_states).max(1)[0].unsqueeze(1)\n",
    "\n",
    "\n",
    "        loss = self.loss_fn(current_q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "        \n",
    "\n",
    "    def train_agent(self, episodes=1000, target_update_frequency=10):\n",
    "        total_rewards = []\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "                self.buffer.push((state, action, reward, next_state, done))\n",
    "                self.train()\n",
    "\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            total_rewards.append(total_reward)\n",
    "\n",
    "            if episode % target_update_frequency == 0:\n",
    "                self.update_target_model()\n",
    "\n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "\n",
    "            if episode % 10 == 0:\n",
    "                print(f\"Episode {episode}, Total Reward: {total_reward}, Epsilon: {self.epsilon}\")\n",
    "\n",
    "        return total_rewards\n",
    "\n",
    "    def test_agent(self, episodes=10):\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = self.select_action(state)\n",
    "                state, reward, done, _ = self.env.step(action)\n",
    "                total_reward += reward\n",
    "\n",
    "            print(f\"Test Episode {episode}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Create Mountain Car environment\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "# Initialize DQNAgent\n",
    "agent = DQNAgent(env)\n",
    "\n",
    "# Train the agent\n",
    "total_rewards = agent.train_agent(episodes=500)\n",
    "\n",
    "# Test the agent\n",
    "agent.test_agent()\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy (random, before training):\n",
      "00,0,[+0.81 -0.19 -0.45] 01,0,[+1.57 -2.77 +0.35] Policy (trained):\n",
      "00,0,[+0.81 -0.19 -0.45] 01,0,[+1.57 -2.77 +0.35] "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_states, h1_nodes, out_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define network layers\n",
    "        self.fc1 = nn.Linear(in_states, h1_nodes)\n",
    "        self.out = nn.Linear(h1_nodes, out_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Define memory for Experience Replay\n",
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "    \n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Mountain Car Deep Q-Learning\n",
    "class MountainCarDQL():\n",
    "    # Hyperparameters (adjustable)\n",
    "    learning_rate_a = 0.001\n",
    "    discount_factor_g = 0.9\n",
    "    network_sync_rate = 10\n",
    "    replay_memory_size = 1000\n",
    "    mini_batch_size = 32\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = None\n",
    "\n",
    "    ACTIONS = [0, 1, 2]  # 0: push left, 1: no push, 2: push right\n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_low = [-1.2, -0.07]\n",
    "        self.state_high = [0.6, 0.07]\n",
    "\n",
    "    def train(self, episodes, render=False):\n",
    "        env = gym.make('MountainCar-v0')\n",
    "        num_states = env.observation_space.shape[0]\n",
    "        num_actions = len(self.ACTIONS)\n",
    "\n",
    "        epsilon = 1\n",
    "        memory = ReplayMemory(self.replay_memory_size)\n",
    "\n",
    "        policy_dqn = DQN(in_states=num_states, h1_nodes=num_states, out_actions=num_actions)\n",
    "        target_dqn = DQN(in_states=num_states, h1_nodes=num_states, out_actions=num_actions)\n",
    "        target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "\n",
    "        print('Policy (random, before training):')\n",
    "        self.print_dqn(policy_dqn)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(policy_dqn.parameters(), lr=self.learning_rate_a)\n",
    "\n",
    "        rewards_per_episode = np.zeros(episodes)\n",
    "        epsilon_history = []\n",
    "        step_count = 0\n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "\n",
    "            state = self.normalize_state(state)\n",
    "\n",
    "            while not terminated and not truncated:\n",
    "                if random.random() < epsilon:\n",
    "                    action = random.choice(self.ACTIONS)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        q_values = policy_dqn(torch.FloatTensor(state)).numpy()\n",
    "                        action = np.argmax(q_values)\n",
    "\n",
    "                new_state, reward, terminated, _ = env.step(self.ACTIONS[action])\n",
    "                new_state = self.normalize_state(new_state)\n",
    "\n",
    "                memory.append((state, action, new_state, reward, terminated))\n",
    "\n",
    "                state = new_state\n",
    "                step_count += 1\n",
    "\n",
    "            if reward == 1:\n",
    "                rewards_per_episode[i] = 1\n",
    "\n",
    "            if len(memory) > self.mini_batch_size and np.sum(rewards_per_episode) > 0:\n",
    "                mini_batch = memory.sample(self.mini_batch_size)\n",
    "                self.optimize(mini_batch, policy_dqn, target_dqn)\n",
    "\n",
    "                epsilon = max(epsilon - 1 / episodes, 0)\n",
    "                epsilon_history.append(epsilon)\n",
    "\n",
    "                if step_count > self.network_sync_rate:\n",
    "                    target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "                    step_count = 0\n",
    "\n",
    "        env.close()\n",
    "\n",
    "        torch.save(policy_dqn.state_dict(), \"mountain_car_dql.pt\")\n",
    "\n",
    "        plt.figure(1)\n",
    "        sum_rewards = np.zeros(episodes)\n",
    "        for x in range(episodes):\n",
    "            sum_rewards[x] = np.sum(rewards_per_episode[max(0, x - 100):(x + 1)])\n",
    "        plt.subplot(121)\n",
    "        plt.plot(sum_rewards)\n",
    "        plt.subplot(122)\n",
    "        plt.plot(epsilon_history)\n",
    "        plt.savefig('mountain_car_dql.png')\n",
    "\n",
    "    def optimize(self, mini_batch, policy_dqn, target_dqn):\n",
    "        num_states = policy_dqn.fc1.in_features\n",
    "\n",
    "        current_q_list = []\n",
    "        target_q_list = []\n",
    "\n",
    "        for state, action, new_state, reward, terminated in mini_batch:\n",
    "            if terminated:\n",
    "                target = torch.FloatTensor([reward])\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    target = torch.FloatTensor(\n",
    "                        reward + self.discount_factor_g * target_dqn(torch.FloatTensor(new_state)).max()\n",
    "                    )\n",
    "\n",
    "            current_q = policy_dqn(torch.FloatTensor(state))\n",
    "            current_q_list.append(current_q)\n",
    "\n",
    "            target_q = target_dqn(torch.FloatTensor(state))\n",
    "            target_q[action] = target\n",
    "            target_q_list.append(target_q)\n",
    "\n",
    "        loss = self.loss_fn(torch.stack(current_q_list), torch.stack(target_q_list))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def state_to_dqn_input(self, state):\n",
    "        return torch.FloatTensor(state)\n",
    "\n",
    "    def normalize_state(self, state):\n",
    "        normalized_state = (state - np.array(self.state_low)) / (np.array(self.state_high) - np.array(self.state_low))\n",
    "        return normalized_state\n",
    "\n",
    "    def test(self, episodes):\n",
    "        env = gym.make('MountainCar-v0')\n",
    "        num_states = env.observation_space.shape[0]\n",
    "        num_actions = len(self.ACTIONS)\n",
    "\n",
    "        policy_dqn = DQN(in_states=num_states, h1_nodes=num_states, out_actions=num_actions)\n",
    "        policy_dqn.load_state_dict(torch.load(\"mountain_car_dql.pt\"))\n",
    "        policy_dqn.eval()\n",
    "\n",
    "        print('Policy (trained):')\n",
    "        self.print_dqn(policy_dqn)\n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()\n",
    "            state = self.normalize_state(state)\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "\n",
    "            while not terminated and not truncated:\n",
    "                with torch.no_grad():\n",
    "                    q_values = policy_dqn(torch.FloatTensor(state)).numpy()\n",
    "                    action = np.argmax(q_values)\n",
    "\n",
    "                new_state, _, terminated, _ = env.step(self.ACTIONS[action])\n",
    "                new_state = self.normalize_state(new_state)\n",
    "\n",
    "                state = new_state\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    def print_dqn(self, dqn):\n",
    "        num_states = dqn.fc1.in_features\n",
    "\n",
    "        for s in range(num_states):\n",
    "            q_values = ''\n",
    "            for q in dqn(torch.FloatTensor(self.normalize_state([s]))).tolist():\n",
    "                q_values += \"{:+.2f}\".format(q) + ' '\n",
    "            q_values = q_values.rstrip()\n",
    "\n",
    "            best_action = self.ACTIONS[dqn(torch.FloatTensor(self.normalize_state([s]))).argmax()]\n",
    "\n",
    "            print(f'{s:02},{best_action},[{q_values}]', end=' ')\n",
    "            if (s + 1) % 4 == 0:\n",
    "                print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mountain_car = MountainCarDQL()\n",
    "    mountain_car.train(3000)\n",
    "    mountain_car.test(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.activations import relu, linear\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import math\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_dim, output_dim, lr):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.Qpolicy = self.create()\n",
    "        self.Qtarget = self.create() \n",
    "        self.Qtarget.set_weights(self.Qpolicy.get_weights())\n",
    "        \n",
    "    def create(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, input_dim = self.input_dim, activation = 'relu'))\n",
    "        model.add(Dense(256, activation = 'relu'))\n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(self.output_dim, activation = 'linear'))\n",
    "        model.compile(optimizer = RMSprop(lr = self.lr, rho = 0.95, epsilon = 0.01), loss = \"mse\", metrics = ['accuracy'])\n",
    "        return model\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, lr = 2.5e-4, gamma = 0.99, epsilon = 1, decay_coe = 0.99975, min_eps = 0.001, \n",
    "                 batch_size = 64, memory_size = 10_000, episodes = 5_000, C = 5):\n",
    "        \n",
    "        self.env = gym.make('MountainCar-v0')\n",
    "\n",
    "        self.states = len(env.observation_space.low)\n",
    "        self.n_actions = env.action_space.n\n",
    "        \n",
    "        self.actions = [i for i in range(self.n_actions)]\n",
    "        \n",
    "        self.lr = lr \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon \n",
    "        self.decay_coe = decay_coe\n",
    "        self.min_eps = min_eps\n",
    "        self.episodes = episodes\n",
    "        self.batch_size = batch_size\n",
    "        self.D = deque(maxlen = memory_size) # replay memory \n",
    "        self.C = C\n",
    "        \n",
    "        self.terminal_state = False # end of the episode\n",
    "        self.target_counter = 0 \n",
    "        \n",
    "        # Plot data\n",
    "        self.timestep = self.episodes / 10\n",
    "        self.history = [] \n",
    "        self.reward_data = []\n",
    "        self.epsilon_data = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.model = Model(self.states, self.n_actions, self.lr)\n",
    "        # Smooth epsilon \n",
    "        self.a = 0.35\n",
    "        self.b = 0.1\n",
    "        self.c = 0.01\n",
    "        \n",
    "    def state_shape(self,states):\n",
    "        states = np.array(states)\n",
    "        return states.reshape(-1,*states.shape)\n",
    "    \n",
    "    def decrement_epsilon(self, time):\n",
    "        '''\n",
    "        if self.epsilon > self.min_eps:\n",
    "            self.epsilon *= self.decay_coe\n",
    "        else:\n",
    "            self.epsilon = self.min_eps\n",
    "        '''\n",
    "        s_time = (time - self.a*self.episodes) / (self.b*self.episodes) \n",
    "        cosh = np.cosh(math.exp(-s_time))\n",
    "        self.epsilon = 1 - (1/cosh + (time*self.c/self.episodes))\n",
    "\n",
    "    def update_D(self, s, a, r, s_, done):\n",
    "        self.D.append([self.state_shape(s), a, r, self.state_shape(s_), done])\n",
    "        \n",
    "    def choose_action(self, states):\n",
    "        if np.random.random() > (1 - self.epsilon):\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            states = self.state_shape(states)\n",
    "            action = np.argmax(self.model.Qpolicy.predict(states))\n",
    "            \n",
    "        return action\n",
    "            \n",
    "    def minibatch(self):\n",
    "        return random.sample(self.D, self.batch_size)\n",
    "    \n",
    "    def graphs(self, episode):\n",
    "        f1 = plt.figure(1)\n",
    "        plt.plot([i for i in range(len(self.reward_data))], self.reward_data)\n",
    "        plt.ylabel('Score per episode')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.savefig(r'RL/reward - e{}v2.png'.format(episode), dpi = 500)\n",
    "        \n",
    "        f2 = plt.figure(2)\n",
    "        plt.plot([i for i in range(len(self.epsilon_data))], self.epsilon_data)\n",
    "        plt.ylabel('Epsilon')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.savefig(r'RL/epsilon - e{}v2.png'.format(episode), dpi = 500)\n",
    "        \n",
    "        f3 = plt.figure(3)\n",
    "        plt.plot([i for i in range(len(self.history))], self.history)\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.savefig(r'RL/loss - e{}v2.png'.format(episode), dpi = 500)\n",
    "        \n",
    "    def train(self):\n",
    "        # X - states passed to the NN, y - target\n",
    "        \n",
    "        X, y = [], []\n",
    "        \n",
    "        if len(self.D) >= self.batch_size: \n",
    "            SARS = self.minibatch()\n",
    "        \n",
    "            s = self.state_shape([row[0] for row in SARS])\n",
    "            qvalue = self.model.Qpolicy.predict(s)[0]\n",
    "\n",
    "            s_ = self.state_shape([row[3] for row in SARS])\n",
    "            future_qvalue = self.model.Qtarget.predict(s_)[0]\n",
    "\n",
    "            for index, (state, action, reward, state_, done) in enumerate(SARS):\n",
    "                if done == True:\n",
    "                    Qtarget = reward\n",
    "                else:\n",
    "                    Qtarget = reward + self.gamma * np.max(future_qvalue[index])\n",
    "            \n",
    "                \n",
    "                qcurr = qvalue[index][0]\n",
    "                qcurr[action] = Qtarget                \n",
    "                X.append(state)\n",
    "                y.append(qcurr)\n",
    "                \n",
    "            X, y = np.array(X).reshape(1,self.batch_size,1,self.states), np.array(y).reshape(1,self.batch_size, 1, self.n_actions)\n",
    "                                        \n",
    "            loss = self.model.Qpolicy.fit(X, y, batch_size = self.batch_size, shuffle = False, verbose = 0)\n",
    "            self.history.append(loss.history['loss'][0])\n",
    "            \n",
    "                \n",
    "            if self.terminal_state:\n",
    "                self.target_counter+=1\n",
    "\n",
    "            # C -> target network update frequency\n",
    "            if self.target_counter > self.C: \n",
    "                self.model.Qtarget.set_weights(self.model.Qpolicy.get_weights())\n",
    "                self.target_counter = 0 \n",
    "            \n",
    "        \n",
    "    def training(self):\n",
    "        timestep_reward = 0\n",
    "        \n",
    "        for episode in tqdm(range(1, self.episodes+1), ascii = True, unit = 'episode'): \n",
    "            s = self.env.reset()\n",
    "            done = False\n",
    "            score = 0\n",
    "            while done != True:\n",
    "                a = self.choose_action(s)\n",
    "                \n",
    "                s_, r, done, _= self.env.step(a)\n",
    "                \n",
    "                # Update \n",
    "                self.terminal_state = done\n",
    "                self.update_D(s,a,r,s_,done)\n",
    "                \n",
    "                self.train()\n",
    "                \n",
    "                s = s_\n",
    "                score += r\n",
    "                \n",
    "            self.decrement_epsilon(episode)  \n",
    "\n",
    "            # UPDATE\n",
    "            self.reward_data.append(score)\n",
    "            self.epsilon_data.append(self.epsilon)\n",
    "            \n",
    "            if episode % self.timestep == 0: \n",
    "                self.graphs(episode)\n",
    "            \n",
    "         \n",
    "        \n",
    "        self.graphs(episode)\n",
    "        self.model.Qpolicy.save(r'RL/{}'.format())\n",
    "        \n",
    "    def test(self, model_name,test_episodes = 100):\n",
    "        model = tf.keras.models.load_model('{}'.format(model_name))\n",
    "        reward = []\n",
    "        self.epsilon = 0.05\n",
    "        for i in range(test_episodes):\n",
    "            ep_reward = 0\n",
    "            s = self.env.reset()\n",
    "            done = False\n",
    "\n",
    "            while done != True:\n",
    "                if np.random.random() > self.epsilon: \n",
    "                    \n",
    "                    s_, r, done, _ = self.env.step(a)\n",
    "                    \n",
    "                    s = s_\n",
    "                    ep_reward += r  \n",
    "                    \n",
    "            reward.append(ep_reward)\n",
    "        \n",
    "        plt.plot([i for i in range(len(reward))], reward)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Episode reward')\n",
    "        plt.savefig(r'RL/Test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
      "  0%|          | 0/1000 [00:00<?, ?episode/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 64, 1, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dqn \u001b[38;5;241m=\u001b[39m DQNAgent(episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1_000\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[123], line 178\u001b[0m, in \u001b[0;36mDQNAgent.training\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_state \u001b[38;5;241m=\u001b[39m done\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_D(s,a,r,s_,done)\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m s \u001b[38;5;241m=\u001b[39m s_\n\u001b[0;32m    181\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n",
      "Cell \u001b[1;32mIn[123], line 130\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m SARS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch()\n\u001b[0;32m    129\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_shape([row[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m SARS])\n\u001b[1;32m--> 130\u001b[0m qvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    132\u001b[0m s_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_shape([row[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m SARS])\n\u001b[0;32m    133\u001b[0m future_qvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mQtarget\u001b[38;5;241m.\u001b[39mpredict(s_)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileojj5vi81.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\guilh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 64, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "dqn = DQNAgent(episodes = 1_000)\n",
    "dqn.training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
